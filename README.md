# My files
clsm_keras_v2.py-----test tokenizer of keras and tflearn
clsm_keras_v3.py-----make train data, havent fit model, use tflearn as tokenizer tool
clsm_keras_v4.py-----add fit model, train and test

# Deep Semantic Similarity Model
My Keras implementation of the Deep Semantic Similarity Model (DSSM)/Convolutional Latent Semantic Model (CLSM) described [here](http://research.microsoft.com/pubs/226585/cikm2014_cdssm_final.pdf).

## Additional References
1. http://research.microsoft.com/pubs/238873/wsdm2015.v3.pdf - slides giving a high level overview of the DSSM and how it can be used for information retrieval.
2. http://research.microsoft.com/en-us/projects/dssm/ - Microsoft Research's summary of the DSSM (includes many more references).
